/***********************************************************************
 * Copyright (c) 2015 by Regents of the University of Minnesota.
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Apache License, Version 2.0 which
 * accompanies this distribution and is available at
 * http://www.opensource.org/licenses/apache2.0.php.
 *
 *************************************************************************/
package edu.umn.cs.spatialHadoop.visualization;

import java.io.IOException;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

import edu.umn.cs.spatialHadoop.util.FSUtil;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.LocalJobRunner;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.output.NullOutputFormat;

import edu.umn.cs.spatialHadoop.OperationsParams;
import edu.umn.cs.spatialHadoop.core.Rectangle;
import edu.umn.cs.spatialHadoop.core.Shape;
import edu.umn.cs.spatialHadoop.mapreduce.SpatialInputFormat3;
import edu.umn.cs.spatialHadoop.operations.FileMBR;

/**
 * Generates a multilevel image based on the adaptive index that combines data
 * and image tiles.
 *
 * @author Ahmed Eldawy
 */
public class AdaptiveMultilevelPlot {
  private static final Log LOG = LogFactory.getLog(AdaptiveMultilevelPlot.class);
  /** Configuration entry for input MBR */
  private static final String InputMBR = "mbr";

  /** Maximum height for a pyramid to be generated by one machine */
  public static final String MaxLevelsPerReducer = "MultilevelPlot.MaxLevelsPerMachine";

  /** The maximum z on which flat partitioning can be used */
  public static final String FlatPartitioningLevelThreshold = "MultilevelPlot.FlatPartitioningLevelThreshold";

  public static final String HistogramFileName = "MultilevelPlot.HistogramFileName";

  public static final String DataTileThreshold = "threshold";

  public static final String TilesToProcess = "AdaptiveMultilevelPlot.TilesToProcess";

  /** The classes of tiles according to our design */
  public enum TileClass {ImageTile, DataTile, ShallowTile, EmptyTile};

  /**
   * A map function for adaptive multilevel plot using flat partitioning for image tiles.
   * It takes each record, plots it to all overlapping image-tiles in the pyramid,
   * and writes the generated partial images (canvases) to the output.
   * Overlaps between the input records and non-image tiles are simply ignored
   * as they are the responsibility of FlatPartitionMapData.
   */
  public static class PartialImageTileCreator extends Mapper<Rectangle, Iterable<? extends Shape>, TileIndex, Canvas> {
    /** The subpyramid that defines the tiles of interest*/
    private SubPyramid subPyramid;

    /** Fixed width for one tile */
    private int tileWidth;

    /** Fixed height for one tile */
    private int tileHeight;

    /** Whether the configured plotter supports smooth or not */
    private boolean smooth;

    /** The plotter associated with this job */
    private Plotter plotter;

    /** A histogram for the size of the input data used to classify tiles */
    private GridHistogram histogram;

    /** The threshold on the data size that defines data and image tiles */
    private long threshold;

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
      super.setup(context);
      Configuration conf = context.getConfiguration();
      // Create the sub-pyramid that defines the range of tiles in interest
      String[] strLevels = conf.get("levels", "7").split("\\.\\.");
      int minLevel, maxLevel;
      if (strLevels.length == 1) {
        minLevel = 0;
        maxLevel = Integer.parseInt(strLevels[0]);
      } else {
        minLevel = Integer.parseInt(strLevels[0]);
        maxLevel = Integer.parseInt(strLevels[1]);
      }
      Rectangle inputMBR = (Rectangle) OperationsParams.getShape(conf, InputMBR);
      subPyramid = new SubPyramid(inputMBR, minLevel, maxLevel, 0, 0, 1 << maxLevel, 1 << maxLevel);

      // Create the configured plotter and retrieve other parameters
      this.plotter = Plotter.getPlotter(conf);
      this.smooth = plotter.isSmooth();
      this.tileWidth = conf.getInt("tilewidth", 256);
      this.tileHeight = conf.getInt("tileheight", 256);

      // Read the histogram and the threshold
      Path histogramFile = new Path(conf.get(HistogramFileName));
      histogram = GridHistogram.readFromFile(histogramFile.getFileSystem(conf), histogramFile);
      histogram.computePrefixSums();
      this.threshold = conf.getLong(DataTileThreshold, 1024 * 1024);
    }

    @Override
    protected void map(Rectangle key, Iterable<? extends Shape> shapes, Context context) throws IOException, InterruptedException {
      if (smooth)
        shapes = plotter.smooth(shapes);
      Map<TileIndex, Canvas> canvasLayers = new HashMap<TileIndex, Canvas>();
      createTiles(shapes, subPyramid, tileWidth, tileHeight, plotter, histogram, threshold, canvasLayers, null);
      // Write all created layers to the output
      LOG.info("Writing "+canvasLayers.size()+" partial images");
      for (Map.Entry<TileIndex, Canvas> entry : canvasLayers.entrySet()) {
        context.write(entry.getKey(), entry.getValue());
      }
    }
  }

  /**
   * A reduce function that merges partial canvases into a final canvas that
   * is written to the output. The input is a tile index and a list of canvases
   * while the output is the same tile index and one canvas that is the result
   * of merging all the partial canvases
   */
  public static class ImageTileMerger extends Reducer<TileIndex, Canvas, TileIndex, Canvas> {
    /** The MBR of the input area to draw */
    private Rectangle inputMBR;

    /** The plotter associated with this job */
    private Plotter plotter;

    /** Fixed width for one tile */
    private int tileWidth;

    /** Fixed height for one tile */
    private int tileHeight;

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
      super.setup(context);
      Configuration conf = context.getConfiguration();
      String[] strLevels = conf.get("levels", "7").split("\\.\\.");
      this.inputMBR = (Rectangle) OperationsParams.getShape(conf, InputMBR);
      this.tileWidth = conf.getInt("tilewidth", 256);
      this.tileHeight = conf.getInt("tileheight", 256);
      this.plotter = Plotter.getPlotter(conf);
    }

    @Override
    protected void reduce(TileIndex tileID, Iterable<Canvas> interLayers, Context context)
        throws IOException, InterruptedException {
      Rectangle tileMBR = tileID.getMBR(inputMBR);
      Canvas finalLayer = plotter.createCanvas(tileWidth, tileHeight, tileMBR);
      for (Canvas interLayer : interLayers) {
        plotter.merge(finalLayer, interLayer);
        context.progress();
      }

      context.write(tileID, finalLayer);
    }
  }

  /**
   * A map function that partitions the data using the fine-grained pyramid
   * partitioning scheme. It only partitions the records that belong to
   * data tiles. This function is used to create data tiles in the top levels
   * of the pyramid.
   */
  public static class PyramidDataTilePartitioner extends Mapper<Rectangle, Iterable<? extends Shape>, TileIndex, Shape> {

    /** The sub-pyramid that represents the tiles of interest */
    private SubPyramid subPyramid;

    /** A histogram for the size of the input data used to classify tiles */
    private GridHistogram histogram;

    /** The threshold on the data size that defines data and image tiles */
    private long threshold;

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
      super.setup(context);
      Configuration conf = context.getConfiguration();
      String[] strLevels = conf.get("levels", "7").split("\\.\\.");
      int minLevel, maxLevel;
      if (strLevels.length == 1) {
        minLevel = 0;
        maxLevel = Integer.parseInt(strLevels[0]);
      } else {
        minLevel = Integer.parseInt(strLevels[0]);
        maxLevel = Integer.parseInt(strLevels[1]);
      }
      Rectangle inputMBR = (Rectangle) OperationsParams.getShape(conf, InputMBR);
      subPyramid = new SubPyramid(inputMBR, minLevel, maxLevel, 0, 0, 1 << maxLevel, 1 << maxLevel);

      // Read the histogram and the threshold
      Path histogramFile = new Path(conf.get(HistogramFileName));
      histogram = GridHistogram.readFromFile(histogramFile.getFileSystem(conf), histogramFile);
      histogram.computePrefixSums();
      this.threshold = conf.getLong(DataTileThreshold, 1024 * 1024);
    }

    @Override
    protected void map(Rectangle partition, Iterable<? extends Shape> shapes, Context context)
        throws IOException, InterruptedException {
      // Use the create tiles function
      // Setting the plotter to null ensures that image tiles are skipped
      createTiles(shapes, subPyramid, 0, 0, null,
          histogram, threshold, null, context);
    }
  }

  /**
   * A map function for adaptive multilevel plot using flat partitioning for data tiles.
   * It takes each record, and replicates it to select overlapping pyramid tiles
   * as defined by the coarse-grained pyramid partitioning logic.
   */
  public static class PyramidPartitioner extends Mapper<Rectangle, Iterable<? extends Shape>, TileIndex, Shape> {

    /** The sub-pyramid that represents the tiles of interest */
    private SubPyramid subPyramid;

    /** Maximum number of levels to assign to one reducer (parameter k in the paper)*/
    private int maxLevelsPerReducer;

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
      super.setup(context);
      Configuration conf = context.getConfiguration();
      String[] strLevels = conf.get("levels", "7").split("\\.\\.");
      int minLevel, maxLevel;
      if (strLevels.length == 1) {
        minLevel = 0;
        maxLevel = Integer.parseInt(strLevels[0]);
      } else {
        minLevel = Integer.parseInt(strLevels[0]);
        maxLevel = Integer.parseInt(strLevels[1]);
      }
      this.maxLevelsPerReducer = conf.getInt(MaxLevelsPerReducer, 3);
      // Adjust the maximum z according to the maxLevelsPerReducer (k) parameter
      // such that we cover the range of levels of interest and the minimum z
      // to replicate to is the same as the minimum z of interest
      maxLevel -= (maxLevel - minLevel) % maxLevelsPerReducer;
      Rectangle inputMBR = (Rectangle) OperationsParams.getShape(conf, InputMBR);
      subPyramid = new SubPyramid(inputMBR, minLevel, maxLevel, 0, 0, 1 << maxLevel, 1 << maxLevel);
    }

    @Override
    protected void map(Rectangle partition, Iterable<? extends Shape> shapes, Context context)
        throws IOException, InterruptedException {
      java.awt.Rectangle overlaps = new java.awt.Rectangle();
      TileIndex outKey = new TileIndex();
      int i = 0;
      for (Shape shape : shapes) {
        Rectangle shapeMBR = shape.getMBR();
        if (shapeMBR == null)
          continue;
        subPyramid.getOverlappingTiles(shapeMBR, overlaps);
        // Iterate over levels from bottom up
        for (outKey.z = subPyramid.maximumLevel; outKey.z >= subPyramid.minimumLevel;
             outKey.z -= maxLevelsPerReducer) {
          for (outKey.x = overlaps.x; outKey.x < overlaps.x
              + overlaps.width; outKey.x++) {
            for (outKey.y = overlaps.y; outKey.y < overlaps.y
                + overlaps.height; outKey.y++) {
              // TODO verify if the subpyramid rooted at outKey contains any non-empty tiles
              context.write(outKey, shape);
            }
          }
          // Shrink overlapping cells to match the upper z
          int updatedX1 = overlaps.x >> maxLevelsPerReducer;
          int updatedY1 = overlaps.y >> maxLevelsPerReducer;
          int updatedX2 = (overlaps.x + overlaps.width - 1) >> maxLevelsPerReducer;
          int updatedY2 = (overlaps.y + overlaps.height - 1) >> maxLevelsPerReducer;
          overlaps.x = updatedX1;
          overlaps.y = updatedY1;
          overlaps.width = updatedX2 - updatedX1 + 1;
          overlaps.height = updatedY2 - updatedY1 + 1;
        }

        if (((++i) & 0xff) == 0)
          context.progress();
      }
    }
  }

  /**
   * A reduce function that takes a tile index and a list of shapes and outputs
   * the final values for that tile and up-to maxLevelsPerReducer below it.
   * The final value could be either shapes (written individually one-by-one)
   * or one canvas that represents the image of that tile
   */
  public static class FinalTileCreator extends Reducer<TileIndex, Shape, TileIndex, Writable> {

    /**The range of levels to consider*/
    private int minLevel, maxLevel;
    /**The MBR of the input dataset*/
    private Rectangle inputMBR;
    /** The user-configured plotter */
    private Plotter plotter;
    /** Maximum levels to generate per reducer */
    private int maxLevelsPerReducer;
    /** Size of each tile in pixels */
    private int tileWidth, tileHeight;
    /** Whether the configured plotter defines a smooth function or not */
    private boolean smooth;

    /** A sub-pyramid object to reuse in reducers*/
    private SubPyramid subPyramid = new SubPyramid();

    /** A histogram for the size of the input data used to classify tiles */
    private GridHistogram histogram;

    /** The threshold on the data size that defines data and image tiles */
    private long threshold;

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
      super.setup(context);
      Configuration conf = context.getConfiguration();
      String[] strLevels = conf.get("levels", "7").split("\\.\\.");
      if (strLevels.length == 1) {
        minLevel = 0;
        maxLevel = Integer.parseInt(strLevels[0]);
      } else {
        minLevel = Integer.parseInt(strLevels[0]);
        maxLevel = Integer.parseInt(strLevels[1]);
      }
      this.maxLevelsPerReducer = conf.getInt(MaxLevelsPerReducer, 3);
      this.inputMBR = (Rectangle) OperationsParams.getShape(conf, InputMBR);
      this.plotter = Plotter.getPlotter(conf);
      this.smooth = plotter.isSmooth();
      this.tileWidth = conf.getInt("tilewidth", 256);
      this.tileHeight = conf.getInt("tileheight", 256);
      // Read the histogram and the threshold
      Path histogramFile = new Path(conf.get(HistogramFileName));
      histogram = GridHistogram.readFromFile(histogramFile.getFileSystem(conf), histogramFile);
      histogram.computePrefixSums();
      this.threshold = conf.getLong(DataTileThreshold, 1024 * 1024);
    }

    @Override
    protected void reduce(TileIndex tileID, Iterable<Shape> shapes, Context context)
        throws IOException, InterruptedException {
      // Create the sub-pyramid associated with the given tileID
      int tileMaxLevel = Math.min(this.maxLevel, tileID.z + maxLevelsPerReducer - 1);
      // The difference between min and max level in this tile
      int levelDifference = tileMaxLevel - tileID.z;
      int c1 = tileID.x << levelDifference;
      int r1 = tileID.y << levelDifference;
      int c2 = c1 + (1 << levelDifference);
      int r2 = r1 + (1 << levelDifference);
      subPyramid.set(inputMBR, tileID.z, tileMaxLevel, c1, r1, c2, r2);

      Map<TileIndex, Canvas> canvasLayers = new HashMap<TileIndex, Canvas>();

      context.setStatus("Plotting");
      if (smooth) {
        shapes = plotter.smooth(shapes);
        context.progress();
      }
      int i = 0;

      createTiles(shapes, subPyramid, tileWidth, tileHeight, plotter,
          histogram, threshold, canvasLayers, context);

      context.setStatus("Writing " + canvasLayers.size() + " tiles");
      // Write all created layers to the output as images
      for (Map.Entry<TileIndex, Canvas> entry : canvasLayers.entrySet()) {
        context.write(entry.getKey(), entry.getValue());
      }
    }
  }

  public static TileClass classifyTile(GridHistogram h, long threshold, int z, int x, int y) {
    float histTileWidth = h.getWidth() / (float)(1 << z);
    float histTileHeight = h.getHeight() / (float)(1 << z);
    int x1 = (int) (x * histTileWidth);
    int y1 = (int) (y * histTileHeight);
    long size = h.getSumOrderOne(x1, y1, histTileWidth, histTileHeight);
    // If the size is larger than the threshold then it has to be an image tile
    if (size > threshold)
      return TileClass.ImageTile;
    // The code below is incorrect because the histogram is not 100% accurate
    //if (size == 0)
    //  return TileClass.EmptyTile;

    // It could be either a data tile or shallow/empty tile based on its parent size
    if (z == 0)
      return TileClass.DataTile; // No parent

    // Compute the size of the parent
    histTileWidth *= 2;
    histTileHeight *= 2;
    x1 = (int) ((x / 2) * histTileWidth);
    y1 = (int) ((y / 2) * histTileHeight);
    long parentSize = h.getSumOrderOne(x1, y1, histTileWidth, histTileHeight);
    if (parentSize > threshold)
      return TileClass.DataTile;

    return TileClass.ShallowTile;
  }

  /**
   * Creates and returns all the tiles in the given sub pyramid that contains
   * the given set of shapes.
   * @param shapes The shapes to be plotted
   * @param subPyramid The subpyramid that defines the range of tiles being considered
   * @param tileWidth Width of each tile in pixels
   * @param tileHeight Height of each tile in pixels
   * @param plotter The plotter used to create canvases
   * @param h A histogram for the input data size
   * @param threshold The threshold used to classify tiles
   * @param tiles The set of tiles that have been created already. It could be
*              empty which indicates no tiles created yet.
   * @param context The context to report progress and write output shapes
   */
  public static void createTiles(
      Iterable<? extends Shape> shapes, SubPyramid subPyramid,
      int tileWidth, int tileHeight,
      Plotter plotter, GridHistogram h, long threshold, Map<TileIndex, Canvas> tiles,
      TaskInputOutputContext context) throws IOException, InterruptedException {
    Rectangle inputMBR = subPyramid.getInputMBR();
    java.awt.Rectangle overlaps = new java.awt.Rectangle();
    TileIndex tileIndex = new TileIndex();
    for (Shape shape : shapes) {
      if (shape == null)
        continue;
      Rectangle mbr = shape.getMBR();
      if (mbr == null)
        continue;

      subPyramid.getOverlappingTiles(mbr, overlaps);
      for (tileIndex.z = subPyramid.maximumLevel; tileIndex.z >= subPyramid.minimumLevel; tileIndex.z--) {
        for (tileIndex.x = overlaps.x; tileIndex.x < overlaps.x + overlaps.width; tileIndex.x++) {
          for (tileIndex.y = overlaps.y; tileIndex.y < overlaps.y + overlaps.height; tileIndex.y++) {
            // Process the tile according to its class
            TileClass tileClass = h == null? null : classifyTile(h, threshold, tileIndex.z, tileIndex.x, tileIndex.y);
            if (plotter!= null && (tileClass == null || tileClass == TileClass.ImageTile)) {
              // Plot the shape on the tile at (z,x,y)
              Canvas c = tiles.get(tileIndex);
              if (c == null) {
                // First time to encounter this tile, create the corresponding canvas
                Rectangle tileMBR = tileIndex.getMBR(inputMBR);
                c = plotter.createCanvas(tileWidth, tileHeight, tileMBR);
                tiles.put(tileIndex.clone(), c);
              }
              plotter.plot(c, shape);
            } else if (context != null && tileClass == TileClass.DataTile) {
              context.write(tileIndex, shape);
            }
          }
        }
        // Update overlappingCells for the higher z
        int updatedX1 = overlaps.x / 2;
        int updatedY1 = overlaps.y / 2;
        int updatedX2 = (overlaps.x + overlaps.width - 1) / 2;
        int updatedY2 = (overlaps.y + overlaps.height - 1) / 2;
        overlaps.x = updatedX1;
        overlaps.y = updatedY1;
        overlaps.width = updatedX2 - updatedX1 + 1;
        overlaps.height = updatedY2 - updatedY1 + 1;

      }
    }
  }

  /**
   * Create an adaptive multilevel plot for the given input by running the correct
   * MapReduce jobs. This method runs the following jobs.
   * <ol>
   *   <li>(If needed) Compute the MBR of the input data</li>
   *   <li>Compute the size histogram of the input</li>
   *   <li>Create image tiles at the top levels using flat partitioning</li>
   *   <li>Create data tiles at the top levels using flat partitioning</li>
   *   <li>Create both data and image tiles at deeper levels using pyramid partitioning</li>
   * </ol>
   * The MBR job runs first. After it is done, the histogram job runs next.
   * After the histogram is computed, the three other jobs run in parallel.
   * @param inPaths
   * @param outPath
   * @param plotterClass
   * @param params
   * @return
   * @throws IOException
   * @throws InterruptedException
   * @throws ClassNotFoundException
   */
  public static Job[] plot(Path[] inPaths, Path outPath, Class<? extends Plotter> plotterClass, OperationsParams params)
      throws IOException, InterruptedException, ClassNotFoundException {
    // Extract the range of levels to generate
    String[] strLevels = params.get("levels", "7").split("\\.\\.");
    int minLevel, maxLevel;
    if (strLevels.length == 1) {
      minLevel = 0;
      maxLevel = Integer.parseInt(strLevels[0]) - 1;
    } else {
      minLevel = Integer.parseInt(strLevels[0]);
      maxLevel = Integer.parseInt(strLevels[1]);
    }
    // Create an output directory that will hold the output of all the jobs
    FileSystem outFS = outPath.getFileSystem(params);
    outFS.mkdirs(outPath);

    // 1- Set or compute the input file MBR
    Rectangle inputMBR = (Rectangle) params.getShape("mbr");
    if (inputMBR == null) {
      // MBR not set, compute it
      OperationsParams fileMBRParams = new OperationsParams(params);
      fileMBRParams.setBoolean("background", false);
      System.err.println("fileMBRParams"+fileMBRParams);
      inputMBR = FileMBR.fileMBR(inPaths, fileMBRParams);
    }

    // Expand input MBR to a square for compatibility with the pyramid structure
    if (params.getBoolean("keepratio", true)) {
      if (inputMBR.getWidth() > inputMBR.getHeight()) {
        inputMBR.y1 -= (inputMBR.getWidth() - inputMBR.getHeight()) / 2;
        inputMBR.y2 = inputMBR.y1 + inputMBR.getWidth();
      } else {
        inputMBR.x1 -= (inputMBR.getHeight() - inputMBR.getWidth()) / 2;
        inputMBR.x2 = inputMBR.x1 + inputMBR.getHeight();
      }
    }
    OperationsParams.setShape(params, InputMBR, inputMBR);

    // ---------------------------
    // 2 - Compute the histogram
    Path histogramFile = new Path(outPath, "histogram");
    long t1 = System.currentTimeMillis();

    Histogram.histogram(inPaths, histogramFile, params);
    params.setInt(Histogram.HistogramWidth, 1 << maxLevel);
    params.setInt(Histogram.HistogramHeight, 1 << maxLevel);
    long t2 = System.currentTimeMillis();
    LOG.info("Computed the histogram in "+(t2-t1)/1000.0+" seconds");
    params.set(HistogramFileName, histogramFile.toString());

    // Now we will run the three plotting jobs
    // First, set the plotter which is used by the three jobs
    Plotter plotter;
    try {
      plotter = plotterClass.newInstance();
      Plotter.setPlotter(params, plotterClass);
    } catch (InstantiationException e) {
      throw new RuntimeException("Error creating plotter", e);
    } catch (IllegalAccessException e) {
      throw new RuntimeException("Error creating plotter", e);
    }

    Job[] plottingJobs = new Job[3];
    int maxLevelWithFlatPartitioning = params.getInt(FlatPartitioningLevelThreshold, 4);

    Path flatImagesPath = new Path(outPath, "flat_images");
    Path flatDataPath = new Path(outPath, "flat_data");
    Path pyramidPath = new Path(outPath, "pyramid");

    if (minLevel <= maxLevelWithFlatPartitioning) {
      // Generate the top levels using the non-spatial partitioning algorithm
      String flatLevels = minLevel + ".." + Math.min(maxLevelWithFlatPartitioning, maxLevel);
      LOG.info("Using flat partitioning in levels " + flatLevels);

      // 3- job for image tiles at the top levels using flat partitioning
      Job flatImagesJob = Job.getInstance(params, "FlatImages");
      flatImagesJob.setJarByClass(AdaptiveMultilevelPlot.class);
      Configuration flatImagesConf = flatImagesJob.getConfiguration();
      flatImagesConf.set("levels", flatLevels);

      // Set input and output
      flatImagesJob.setInputFormatClass(SpatialInputFormat3.class);
      SpatialInputFormat3.setInputPaths(flatImagesJob, inPaths);
      if (flatImagesConf.getBoolean("output", true)) {
        flatImagesJob.setOutputFormatClass(PyramidOutputFormat3.class);
        PyramidOutputFormat3.setOutputPath(flatImagesJob, flatImagesPath);
      } else {
        flatImagesJob.setOutputFormatClass(NullOutputFormat.class);
      }

      // Set map and reduce functions along with intermediate key-value classes
      flatImagesJob.setMapOutputKeyClass(TileIndex.class);
      flatImagesJob.setMapperClass(PartialImageTileCreator.class);
      flatImagesJob.setReducerClass(ImageTileMerger.class);
      flatImagesJob.setMapOutputValueClass(plotter.getCanvasClass());

      // Set number of reducers
      flatImagesJob.setNumReduceTasks(Math.max(1, new JobClient(new JobConf()).getClusterStatus().getMaxReduceTasks() * 7 / 8));
      // Use multithreading in case the job is running locally
      flatImagesConf.setInt(LocalJobRunner.LOCAL_MAX_MAPS, Runtime.getRuntime().availableProcessors());

      // Start the job in the background
      flatImagesJob.submit();
      plottingJobs[0] = flatImagesJob;

      // ----------------------------------------------------------------------
      // 4- job for data tiles at the top levels using flat partitioning
      // TODO we can check the histogram to verify if there are such tiles or not
      Job flatDataJob = Job.getInstance(params, "FlatData");
      flatDataJob.setJarByClass(AdaptiveMultilevelPlot.class);
      Configuration flatDataConf = flatDataJob.getConfiguration();
      flatDataConf.set("levels", flatLevels);

      // Set input and output
      flatDataJob.setInputFormatClass(SpatialInputFormat3.class);
      SpatialInputFormat3.setInputPaths(flatDataJob, inPaths);
      if (flatDataConf.getBoolean("output", true)) {
        flatDataJob.setOutputFormatClass(PyramidOutputFormat3.class);
        PyramidOutputFormat3.setOutputPath(flatDataJob, flatDataPath);
      } else {
        flatDataJob.setOutputFormatClass(NullOutputFormat.class);
      }

      // Set map and reduce functions along with intermediate key-value classes
      flatDataJob.setMapperClass(PyramidDataTilePartitioner.class);
      flatDataJob.setMapOutputKeyClass(TileIndex.class);
      flatDataJob.setMapOutputValueClass(
          OperationsParams.getShape(flatDataConf, "shape").getClass());
      // No reduce function is needed. The default identify reduce function is good enough

      // Set number of reducers
      flatDataJob.setNumReduceTasks(Math.max(1, new JobClient(new JobConf()).getClusterStatus().getMaxReduceTasks() * 7 / 8));
      // Use multithreading in case the job is running locally
      flatDataConf.setInt(LocalJobRunner.LOCAL_MAX_MAPS, Runtime.getRuntime().availableProcessors());

      // Start the job in the background
      flatDataJob.submit();
      plottingJobs[1] = flatDataJob;
    }
    // -------------------------------------
    if (maxLevel > maxLevelWithFlatPartitioning) {
      // 5- Generate the bottom levels using the pyramid partitioning algorithm
      String pyramidLevels = (maxLevelWithFlatPartitioning + 1) + ".." + maxLevel;
      LOG.info("Using pyramid partitioning in levels " + pyramidLevels);

      Job pyramidJob = Job.getInstance(params, "AdaptivePyramid");
      pyramidJob.setJarByClass(AdaptiveMultilevelPlot.class);
      Configuration pyramidConf = pyramidJob.getConfiguration();
      pyramidConf.set("levels", pyramidLevels);

      // Set input and output
      pyramidJob.setInputFormatClass(SpatialInputFormat3.class);
      SpatialInputFormat3.setInputPaths(pyramidJob, inPaths);
      if (pyramidConf.getBoolean("output", true)) {
        pyramidJob.setOutputFormatClass(PyramidOutputFormat3.class);
        PyramidOutputFormat3.setOutputPath(pyramidJob, pyramidPath);
      } else {
        pyramidJob.setOutputFormatClass(NullOutputFormat.class);
      }

      // Set intermediate key and value classes
      pyramidJob.setMapOutputKeyClass(TileIndex.class);
      pyramidJob.setMapOutputValueClass(
          OperationsParams.getShape(pyramidConf, "shape").getClass());

      // Set map and reduce functions
      pyramidJob.setMapperClass(PyramidPartitioner.class);
      pyramidJob.setReducerClass(FinalTileCreator.class);

      // Set number of reducers
      pyramidJob.setNumReduceTasks(Math.max(1, new JobClient(new JobConf()).getClusterStatus().getMaxReduceTasks() * 7 / 8));
      // Use multithreading in case the job is running locally
      pyramidConf.setInt(LocalJobRunner.LOCAL_MAX_MAPS, Runtime.getRuntime().availableProcessors());

      // Start the job in the background
      pyramidJob.submit();
      plottingJobs[2] = pyramidJob;
    }
    // Start the jobs and wait for their completion
    for (Job job : plottingJobs) {
      if (job != null)
        job.waitForCompletion(false);
    }
    histogramFile.getFileSystem(params).delete(histogramFile, true);
    // Move all output files to one directory
    FSUtil.mergeAndFlattenPaths(outFS, flatImagesPath, flatDataPath, pyramidPath);

    return plottingJobs;
  }
}
